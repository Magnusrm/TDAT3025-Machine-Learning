{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "oppg_d.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Magnusrm/TDAT3025-Machine-Learning/blob/master/Task2.1/oppg_d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K80N7D6JbRg",
        "colab_type": "code",
        "outputId": "74133ca1-7d30-406e-ab04-3733622385cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "(x_train_, y_train_), (x_test_, y_test_) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "x_train = np.reshape(x_train_, (-1, 28, 28, 1))  # tf.nn.conv2d takes 4D input\n",
        "y_train = np.zeros((y_train_.size, 10))\n",
        "y_train[np.arange(y_train_.size), y_train_] = 1\n",
        "\n",
        "batches = 600  # Divide training data into batches to speed up optimization\n",
        "x_train_batches = np.split(x_train, batches)\n",
        "y_train_batches = np.split(y_train, batches)\n",
        "\n",
        "x_test = np.reshape(x_test_, (-1, 28, 28, 1))\n",
        "y_test = np.zeros((y_test_.size, 10))\n",
        "y_test[np.arange(y_test_.size), y_test_] = 1\n",
        "\n",
        "\n",
        "class ConvolutionalNeuralNetworkModel:\n",
        "    def __init__(self):\n",
        "        # Model input\n",
        "        self.x = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n",
        "        self.y = tf.placeholder(tf.float32)\n",
        "        \n",
        "        conv1 = tf.layers.conv2d(\n",
        "            self.x, \n",
        "            filters=32, \n",
        "            kernel_size=[5, 5], \n",
        "            strides=[1, 1], \n",
        "            padding='same',\n",
        "            activation=tf.nn.relu)\n",
        "        \n",
        "        pool1 = tf.layers.max_pooling2d(conv1, pool_size=[2, 2], strides=[2, 2], padding='same')\n",
        "        \n",
        "        conv2 = tf.layers.conv2d(\n",
        "            pool1, \n",
        "            filters=64, \n",
        "            kernel_size=[5, 5], \n",
        "            strides=[1, 1], \n",
        "            padding=\"same\",\n",
        "            activation=tf.nn.relu)\n",
        "        \n",
        "        pool2 = tf.layers.max_pooling2d(conv2, pool_size=[2, 2], strides=[2, 2], padding='same')\n",
        "        \n",
        "        pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
        "        dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
        "        \n",
        "        dropout = tf.layers.dropout(\n",
        "            inputs=dense, \n",
        "            rate=0.4, \n",
        "            training=True)\n",
        "        \n",
        "        # Logits\n",
        "        logits = tf.layers.dense(inputs=dropout, units=10)\n",
        "        \n",
        "        # Predictor\n",
        "        f = tf.nn.softmax(logits)\n",
        "\n",
        "        # Cross Entropy loss\n",
        "        self.loss = tf.losses.softmax_cross_entropy(self.y, logits)\n",
        "\n",
        "        # Accuracy\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(f, 1), tf.argmax(self.y, 1)), tf.float32))\n",
        "\n",
        "\n",
        "model = ConvolutionalNeuralNetworkModel()\n",
        "\n",
        "# Training: adjust the model so that its loss is minimized\n",
        "minimize_operation = tf.train.AdamOptimizer(0.0001).minimize(model.loss)\n",
        "\n",
        "# Create session object for running TensorFlow operations\n",
        "session = tf.Session()\n",
        "\n",
        "# Initialize tf.Variable objects\n",
        "session.run(tf.global_variables_initializer())\n",
        "\n",
        "for epoch in range(10):\n",
        "    for batch in range(batches):\n",
        "        session.run(minimize_operation, {model.x: x_train_batches[batch], model.y: y_train_batches[batch]})\n",
        "\n",
        "    print(\"epoch\", epoch)\n",
        "    print(\"accuracy\", session.run(model.accuracy, {model.x: x_test, model.y: y_test}))\n",
        "\n",
        "session.close()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From <ipython-input-1-2e64a06d18af>:30: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From <ipython-input-1-2e64a06d18af>:32: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling2D instead.\n",
            "WARNING:tensorflow:From <ipython-input-1-2e64a06d18af>:45: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From <ipython-input-1-2e64a06d18af>:50: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "epoch 0\n",
            "accuracy 0.843\n",
            "epoch 1\n",
            "accuracy 0.8648\n",
            "epoch 2\n",
            "accuracy 0.8773\n",
            "epoch 3\n",
            "accuracy 0.8825\n",
            "epoch 4\n",
            "accuracy 0.8888\n",
            "epoch 5\n",
            "accuracy 0.8941\n",
            "epoch 6\n",
            "accuracy 0.8995\n",
            "epoch 7\n",
            "accuracy 0.8987\n",
            "epoch 8\n",
            "accuracy 0.9022\n",
            "epoch 9\n",
            "accuracy 0.8991\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}